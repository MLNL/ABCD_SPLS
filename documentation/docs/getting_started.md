## Installation

To install the PLS/CCA Toolkit, clone the repository from Github using the following command:

```Bash
git clone https://github.com/anaston/PLS_CCA_framework
```

After the toolkit downloaded, go to the folder containing the toolkit and open MATLAB. In general, we advise you to run all commands from this toolkit folder.

To initialize the toolkit, run the following line in the MATLAB command window:

```MATLAB
set_path
```

## Dependencies

The neuroimaging community has great visualization and other tools, therefore we decided to use some of these available tools for specific purposes in the toolkit. Depending on the analysis and plots you would like to make you will need to download some of the toolboxes below. We recommend two ways of adding toolboxes to your path:

- you can just add the toolboxes to the path in their current location if you already have them on your computer,
- you can add the toolboxes in a dedicated folder inside the toolkit.

For easier management of the dependencies, all toolboxes are stored in a dedicated folder within the toolkit. To create this folder, run the following line in the MATLAB command window:

```MATLAB
mkdir external
```

Importantly, this `external` folder (and its content) is not added to `.gitignore` and thus it are not version controlled by git. On one side, this is to accomodate the specific needs of users and only to use toolboxes that are essential for their specific analyses and plots. On the other side, this is to avoid that the toolkit gets unnecessarily large due to potentially large external toolboxes.

Here is a complete list of toolboxes that you might need for using the toolkit:

- [PALM](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM)
- [SPM](https://www.fil.ion.ucl.ac.uk/spm/software/download/)
- [BrainNet Viewer](https://www.nitrc.org/projects/bnv/)
- [AAL](https://www.gin.cnrs.fr/en/tools/aal/)

To know which dependencies you will need for your specific needs, please see the [Analysis](../analysis/#dependencies) and [Visualization](../visualization/#dependencies) pages.

Now, we demonstrate how to add toolboxes to the toolkit using PALM as example. For this, download PALM manually by the provided link, copy the `PALM` folder into your `external` folder, then finally add PALM to the MATLAB path using the following line in the MATLAB command window:

```MATLAB
set_path('PALM')
```

## Overview

As illustrated in the figure below, the toolkit consists of two main parts:

1. Analysis
2. Visualization

<p align="center">
   <img src="../figures/overview.png" width="531" height="142">
</p>

The reason behind this division is that whereas an analysis can be run on a cluster without a need for a graphical output, the visualization usually takes place on a local computer with a need for a graphical output. Of course, if both the analysis and visualization is done on a local computer, the two can be easily combined as demonstrated in the demos.

Next, we discuss the folder structure of the main inputs and outputs of your analysis and visualization.

<p align="center">
   <img src="../figures/folders.png" width="331" height="449">
</p>

As we can see in the figure, all files are stored in a project folder, which contains a `data` and a `framework` folder. The `data` folder contains our data for this project and the `framework` folder will contain all our results. We need to create the project folder manually and unless we want to use simulated data generated by the toolkit, we also need to create our `data` folder including our two modalities of data in separate files (`X.mat`, `Y.mat`). All these folders and files we need to create are illustrated by a red box in the figure.

All the other folders will be created by the toolkit during analysis. Our specific framework folder will be generated by the toolkit based on your CCA/PLS model and framework choice. For instance, an SPLS analysis with a single holdout set (20% of the data), 10 validation sets (20% of the outer training set) for hyperparameter optimization will generate the `spls_holdout1-0.20_subsamp10-0.20` folder name. If you want to specify a custom name for this analysis, you can change the `cfg.frwork.flag = ''` field from its default value, which will then be appended to your specific framwork name. For instance, `cfg.frwork.flag = '_TEST'` will create the `spls_holdout1-0.20_subsamp10-0.20_TEST` folder. 

In the following section, we will discuss how to run an analysis on a cluster. However, if you want to get started straight away and run an experiment on your local computer, see our following demos: [demo for simulated data](../mfiles/demo_simulation), [demo for structural MRI data](../mfiles/demo_smri), [demo for fMRI data](../mfiles/demo_fmri). Please check out our [Analysis](../analysis) and [Visualization](../visualization) pages if you want to understand more about the toolkit and what are the specific dependencies, inputs and outputs of the core functions. We also highly recommend to go through the defaults of [cfg](../cfg) and [res](../res). Finally, you can find a detailed documentation of each high-level function of the toolkit (see the menu on the left) that you will need for regular use.

## Running on a cluster

The toolkit can be run in multiple MATLAB inscances, e.g., in a cluster environment. If you use SGE or SLURM scheduling systems, you simply need to send the same analysis to different nodes and the toolkit will take care of the rest. If you use a different scheduling system then a one-line modification of the `cfg_defaults` function is needed to account for your scheduling system and you are ready to go. Feel free to get in touch with us to help you set this up. 

Here is a brief description what happens under the hood when the toolkit is running on different MATLAB instances. Although MATLAB can load the same `.mat` file from different MATLAB instances, it cannot save to the same `.mat` file . To work around this, the toolkit appends the unique ID of the computing node/job at the end of each `.mat` file (in a local environment, the ID is set to `_1` by default), so even if different jobs are saving the same content simultaneously, they will do it into different files. In addition, there are a handful of wrapper functions to save, search and load these `.mat` files and the following mechanisms are in place to share computational cost:

- jobs save computations to `.mat` files regularly on disc,
- there is a random seed before each time consuming operation in the toolkit (e.g., grid search and permutation testing), hence different jobs will most likely perform different computations,
- jobs can load `.mat` files computed by other jobs,
- jobs regularly check what `.mat` files are available and they only start a new computation if that has not yet been performed by another job,
- if two MATLAB instances are saving the same computation to a `.mat` file then they will write to different files due to their different job ID-s.

You might ask: Does not this computational strategy create a lot of intermediate and some duplicate files? Indeed, however, there is a `clean_up` function that allows to remove all the intermediate and duplicate files after your analysis. Do not forget to use this as otherwise you might exceed your disc space or have difficulties to move your results around e.g., from a cluster to a local computer.

An extra benefit of this computational strategy is that in case your analysis is aborted (e.g., you run out of allocated time on a cluster), you can always restart the same analysis and it will catch up with the computations where it was aborted.


